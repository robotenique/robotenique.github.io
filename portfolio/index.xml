<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Juliano Garcia</title>
    <link>https://robotenique.github.io/portfolio/</link>
    <description>Recent content in Projects on Juliano Garcia</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 01 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://robotenique.github.io/portfolio/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Study on Gradient Boosting Classifiers</title>
      <link>https://robotenique.github.io/portfolio/tcc/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/tcc/</guid>
      <description>Gradient Boosting Machines (GBMs) is a supervised machine learning algorithm that has been achieving state-of-the-art results in a wide range of different problems and winning machine learning competitions. When building any machine learning model, the hyperparameter optimization can become a costly and time-consuming task depending on the number and the hyperparameter space of the tuning procedure. Machine learning users that are not experienced researchers or data science professionals can struggle to define which hyperparameters and values to choose when starting the model tuning, especially with newer GBMs implementations like the XGBoost and LightGBM library.</description>
    </item>
    
    <item>
      <title>2nd website version</title>
      <link>https://robotenique.github.io/portfolio/website2/</link>
      <pubDate>Sat, 21 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/website2/</guid>
      <description>This was my second website, where I used Jekyll to write a few blog posts.</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Juliano Garcia</title>
    <link>https://robotenique.github.io/portfolio/</link>
    <description>Recent content in Projects on Juliano Garcia</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 01 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://robotenique.github.io/portfolio/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Study on Gradient Boosting Classifiers</title>
      <link>https://robotenique.github.io/portfolio/tcc/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/tcc/</guid>
      <description>Gradient Boosting Machines (GBMs) is a supervised machine learning algorithm that has been achieving state-of-the-art results in a wide range of different problems and winning machine learning competitions. When building any machine learning model, the hyperparameter optimization can become a costly and time-consuming task depending on the number and the hyperparameter space of the tuning procedure. Machine learning users that are not experienced researchers or data science professionals can struggle to define which hyperparameters and values to choose when starting the model tuning, especially with newer GBMs implementations like the XGBoost and LightGBM library.</description>
    </item>
    
    <item>
      <title>Women&#39;s Shoes Prices - Kaggle EDA</title>
      <link>https://robotenique.github.io/portfolio/shoes-eda/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/shoes-eda/</guid>
      <description>The purpose of this project is to study the Women&amp;rsquo;s Shoes Prices dataset from Kaggle, which contains a list of women&amp;rsquo;s shoes and the prices they were sold. The data was originally made available at Kaggle by the Datafiniti Company. This project was done mainly to showcase some basic EDA techniques (like histograms and ECDF) but at the same time diving deep into more complicated business questions, e.g. using Fuzzy matching to find out the most popular shoe colors in the dataset.</description>
    </item>
    
    <item>
      <title>Snacker - AI Recommender System</title>
      <link>https://robotenique.github.io/portfolio/snacker/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/snacker/</guid>
      <description>Snacker is a full-fledged social network for snack lovers all over the world. The website itself was built using the Flask library for the back-end, and the recommendation engine was implemented using a specific collaborative filtering technique called Matrix Factorization. The data was stored using MongoDB for prototyping and testing, more details about the methodology can be found here.</description>
    </item>
    
    <item>
      <title>Incognito Search - Chrome Extension</title>
      <link>https://robotenique.github.io/portfolio/incognito-search/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/incognito-search/</guid>
      <description>Simple Chrome Extension that searches in an Incognito window for the selected text. Built using Javascript.</description>
    </item>
    
    <item>
      <title>Movies Ontology - iMDb</title>
      <link>https://robotenique.github.io/portfolio/movies-ontology/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/movies-ontology/</guid>
      <description>A knowledge-based systems is an area of study in artificial intelligence which tries to capture human knowledge (which usually are experts in the system) and embedded them into rules in a system. In this specific project iMDb data was used to create an ontology of movies, by parsing iMDb datasets and adding them into the ontology. The modelling of the ontology was made with Protégé, an open-source ontology editor, using a Description Logic called the Web Ontology Language (OWL).</description>
    </item>
    
    <item>
      <title>2nd website version</title>
      <link>https://robotenique.github.io/portfolio/website2/</link>
      <pubDate>Sat, 21 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/website2/</guid>
      <description>This was my second website, where I used Jekyll to write a few blog posts.</description>
    </item>
    
    <item>
      <title>Law of Large Numbers Simulator</title>
      <link>https://robotenique.github.io/portfolio/largenumsim/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/largenumsim/</guid>
      <description>This is a project to demonstrate in graph plotting and real data, Weak Law of Large numbers, which is a very useful Theorem used in statistics. As our website says: &amp;quot; In practice, it (the Weak Law of Large Numbers) dictates that, if repeated enough times, the accumulate results of the same experiment will tend to its real mathematical probabilities.&amp;rdquo;
The website plots in real time the graph of throwing a dice or a coin the number of times the user specifies, so it&amp;rsquo;s completely interactive, and the user have fully control over the start number, the amount of throws to perform, and even the speed of the plot.</description>
    </item>
    
    <item>
      <title>1st website version</title>
      <link>https://robotenique.github.io/portfolio/website1/</link>
      <pubDate>Sun, 01 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://robotenique.github.io/portfolio/website1/</guid>
      <description>This was my first website. You can check it out for more projects related to my programming work at high school.</description>
    </item>
    
  </channel>
</rss>